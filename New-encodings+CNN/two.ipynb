{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavit21178/anaconda3/envs/conda_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "from transformers import TFBertModel, BertTokenizer,BertConfig,BertModel\n",
    "import re\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the ProtBert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "\n",
    "# Load the ProtBert model\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('merged_data_modified.csv')\n",
    "y=df['id']\n",
    "x=df['seq']\n",
    "\n",
    "#split the data into train and test\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#oversample the data to create a balanced dataset in train\n",
    "#use random oversampling\n",
    "print(x_train.shape)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train=x_train.values.reshape(-1,1)\n",
    "x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "x_train=x_train.reshape(-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494,) (494,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[re.sub(r\"[UZOB]\", \"X\", seq) for seq in x_train]\n",
    "x_test=[re.sub(r\"[UZOB]\", \"X\", seq) for seq in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a space seaprated string of the sequences\n",
    "for i in range(len(x_train)):\n",
    "    starting_string=x_train[i]\n",
    "    inserting_string=''\n",
    "    for j in range(len(starting_string)):\n",
    "        inserting_string+=starting_string[j]+' '\n",
    "    inserting_string=inserting_string[:-1]\n",
    "    x_train[i]=inserting_string\n",
    "\n",
    "#do the same for the test data\n",
    "for i in range(len(x_test)):\n",
    "    starting_string=x_test[i]\n",
    "    inserting_string=''\n",
    "    for j in range(len(starting_string)):\n",
    "        inserting_string+=starting_string[j]+' '\n",
    "    #remove the last space\n",
    "    inserting_string=inserting_string[:-1]\n",
    "    x_test[i]=inserting_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y G G T P P F V\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/pavit21178/anaconda3/envs/conda_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ids = tokenizer.batch_encode_plus(x_train,max_length=40,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "hidden_states = model(**ids)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1024])\n"
     ]
    }
   ],
   "source": [
    "#get sequence layer\n",
    "sequence_output = hidden_states[0]\n",
    "print(sequence_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([494, 40, 1024])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states.shape)\n",
    "#what is the data type of hidden_states\n",
    "print(type(hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavit21178/anaconda3/envs/conda_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 40, 1024])\n"
     ]
    }
   ],
   "source": [
    "#do same with test data\n",
    "ids = tokenizer.batch_encode_plus(x_test,max_length=40,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "test_hidden_states = model(**ids)[0]\n",
    "print(test_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y G G T P P F V', 'Q L', 'G P G', 'P F P', 'H C H T N', 'K G S L A D E E', 'T A Y', 'F F R P F F R P F F', 'G G N P', 'A D E', 'P F P G P I', 'G G L G', 'R P F F R P F F', 'P P', 'Q L F G P N V N P W H N P', 'P F P G P I P', 'D G', 'D E S', 'Y Q E P V L G P V R G P F P I', 'V Y P', 'D E D', 'R P G', 'E E E Q', 'A P K H K E M P F P K Y P V E P F', 'G I', 'E G G', 'S A E Q K', 'E N', 'V G', 'V D', 'N E N L L', 'F G G F', 'E D V', 'E D', 'R G P F I V', 'F Y P E L F R', 'D P Q', 'R R P P', 'G G R P F F G G', 'G L', 'P V A R M C R', 'E E L', 'V Y P F G G G I N H', 'D D D D', 'Y G Y', 'L E Q L L', 'K P F', 'G R P', 'P A Q', 'P F P G P I P N S', 'R G P F P I V', 'I S', 'Y P', 'L G L', 'F F G G', 'G G P', 'K F', 'Y F', 'N L Q G', 'Q L F N P S T N P W H S P', 'G E', 'Y Q Q P V L G P V R G P F P I', 'R G P P F', 'L R L', 'G G R P F F', 'P G R', 'R G P P G G F F', 'N Y', 'M P F P K Y P V E P F', 'G P F P I I V', 'N G K E T', 'G F F', 'P G P G P G', 'P F', 'G G L G G', 'F F P P', 'D G G', 'E F', 'I I', 'R G P P G F F', 'Y L G Y L E Q L L R', 'R G P P F I V', 'Y Q Q P V L G P V R G P F P I I V', 'A P F P E V F', 'L V', 'Y Y Y', 'M A P K H K E M P F P K Y P V E P F', 'R R', 'G L G G', 'L G G', 'E N E', 'T L R R C M', 'A P F P E V F G', 'V I I P F P G R', 'D E', 'W L', 'V Y P F P P G', 'R G P G P I I V', 'V L', 'P V L G P V R G P F P I I V', 'G Y', 'D D', 'R P P F I V', 'P A A', 'N R T F', 'E A', 'I W', 'V I P F P G R', 'K P', 'I D', 'R G F F', 'V Y P F P P I G N H', 'P G', 'E A G I Q', 'G P V R G P F P I I V', 'V L P T D Q N F I L R', 'I F', 'V P P F L E', 'E L L', 'P K', 'K G D E E S L A', 'R L', 'C A L T P', 'A E', 'L L L L', 'I G', 'V V Y P W T Q R F', 'E D D', 'Q L F G P N V N P W H N P', 'F P', 'L W', 'G G L', 'A D A', 'I P', 'E G', 'S E', 'D E E', 'R G P P F F F', 'Y Y', 'F P P', 'V P L G T Q Y T D A P S F', 'R G P P F I I V', 'R G E N E S D E Q G A I V T', 'I T', 'S F E', 'R G P', 'N A L P E', 'P G P', 'S T M L L E S E R', 'L V Y P F P G P I H N', 'R P G F F', 'V I F P P G R', 'F F P R', 'G P F F', 'G G V', 'S A E F G', 'E L', 'E V', 'L G', 'V Y P F P P G I G G', 'R G P P F I V G G', 'H V', 'P P G', 'F F V A P F P E V F G K', 'Q P V L G P V R G P F P I I V', 'R P F F R P F F R P F F', 'Y L E Q L L R', 'E G F', 'P Y', 'E Q P Q Q N E', 'Y Q E P V L G P V R G P F P I I V', 'K P P F I V', 'G L G', 'G G G G L', 'R G P P G F G', 'L L L', 'G G R G P P F I V', 'V Y', 'R P G G F F', 'K L H E N I A R', 'Y Q Q P V L G P V R G P F P I I', 'L G G G', 'Y E G N S', 'F G G', 'P G I', 'G V', 'V F', 'L D', 'Q S K V L P V P Q', 'L Y E R', 'V D R', 'F F P E', 'F L L', 'Q L F N P S T N P W H S P', 'G L L P D G T P R', 'V P P F L Q', 'A N P G P V R D L R', 'R R P F F', 'V P Y', 'G P F P V I', 'D Y', 'R G P P F I', 'E E E', 'S F', 'V V', 'L L', 'Y L', 'V A', 'Q L F N P S T N P W H', 'G G G L G', 'K G', 'Q V A I A H R D A K', 'A Y F Y P E L', 'R G P K P I I V', 'I L', 'V Y P F P P G I', 'A Q A L Q A Q A', 'R P G F', 'L F', 'P P P', 'W E', 'D E L', 'C M', 'P F I V', 'W P', 'Q E E L', 'R G P P G I G', 'D L', 'Q L F N P S', 'F F', 'E D F', 'G K H Q Q E E E N E G G', 'P G P I P', 'P E T', 'E G S', 'V V G E T', 'R G P P G F', 'Y P F P G P I', 'W W W', 'V T A D E S Q Q D V L K', 'F I', 'R G P P G G G F F', 'P P F I V', 'P A', 'A L E P D H R', 'E D G', 'L A', 'K G N E E S L A', 'F Y P E L F', 'G N P D I E H P', 'L V G', 'F P K', 'D A', 'V I F P P G', 'G C G', 'A Q T Q S L V Y P F P G P I P N S L P Q N I P P L T Q', 'S E E', 'V V V', 'A A P Y', 'L I', 'W F', 'P I P', 'P V L G P V', 'Q Q P V L G P V R G P F P I', 'Q N D K I H P F A Q T Q S L V Y P F G P I P', 'P I', 'F W', 'D L L', 'R G P F P I I V', 'G L G G G', 'L L G', 'F F P G G', 'I E', 'R P F F G G', 'K A V P Y P P Q', 'Y G', 'K G R Y E R', 'F I V', 'F G', 'R P P P F F F', 'V I', 'E E D G K', 'A L P E E V', 'V A V', 'G P P F I V', 'C C N K S V', 'E G S E A P D G S S R', 'P L', 'E N I N E L', 'G G F F G G', 'L E Q L', 'V E V', 'R R P P F F', 'D Q R', 'G F G', 'G R', 'F L', 'L S E R Y P', 'E V L N', 'R P L G N C', 'P F P P', 'L Y', 'G G F', 'R P F F', 'R F', 'G P P F', 'R G P P G G V', 'R G P P G G F', 'G G V V V', 'N F N N Q L D Q Q T P R', 'G G Y', 'P S E', 'L G A G G S L A', 'K P K', 'E P A D', 'Q L F N P S T N P W H', 'V Y P F P P G I N H', 'R P F G', 'E T', 'E P', 'Y Y G', 'F Y', 'T D V E N L H L P P L L', 'E I N E L', 'G G R G P P F I V G G', 'R P F', 'I Q', 'S L', 'F G F G', 'G V V', 'A G N P D I E H P E', 'R G P P F G G', 'G L Y', 'R G P P F F', 'V V V P P F L Q P', 'G F', 'Y P F P G P I H N S', 'T E S S S E', 'T E', 'E P E', 'E Y', 'E I', 'G P', 'A F', 'P R', 'A S N M S D L', 'R P K H P I K H Q', 'V R S Y', 'A D', 'I K', 'G Y Y', 'R D M P I Q A F L L Y', 'G E G', 'A S N M S D L', 'E G F', 'G G Y', 'V D', 'V V G E T', 'V V', 'D D D D', 'A S N M S D L', 'A L P E E V', 'E N I N E L', 'K G N E E S L A', 'K G N E E S L A', 'L E Q L', 'T E', 'V R S Y', 'N Y', 'H C H T N', 'P A Q', 'V F', 'Q L', 'L E Q L', 'D E', 'R L', 'Q L', 'A Q A L Q A Q A', 'S F', 'D D D D', 'N R T F', 'L V G', 'V P Y', 'P A Q', 'V E V', 'E L', 'L S E R Y P', 'E E E', 'A D A', 'R P L G N C', 'S F', 'A A P Y', 'V D', 'K G', 'K G', 'S F E', 'K G', 'H V', 'V D R', 'A Q A L Q A Q A', 'H C H T N', 'E P E', 'H V', 'A D E', 'D D D D', 'V T A D E S Q Q D V L K', 'C A L T P', 'D P Q', 'K G S L A D E E', 'V E V', 'S F', 'V G', 'D E S', 'D Q R', 'V F', 'Q L', 'V A V', 'R P L G N C', 'S F', 'E G S', 'S E', 'D G', 'S F E', 'E A G I Q', 'G C G', 'K G R Y E R', 'V L P T D Q N F I L R', 'E V', 'V R S Y', 'K G S L A D E E', 'Q L', 'G G N P', 'L Y E R', 'G E G', 'K G S L A D E E', 'L Y E R', 'G G Y', 'Q V A I A H R D A K', 'D P Q', 'D Q R', 'S E', 'E A', 'E D G', 'K G', 'T E', 'V G', 'L G A G G S L A', 'S T M L L E S E R', 'V D', 'V V G E T', 'G C G', 'E N I N E L', 'K G', 'A E', 'C C N K S V', 'A A P Y', 'E E D G K', 'V F', 'N Y', 'D G G', 'V E V', 'S F', 'E D D', 'T L R R C M', 'V D', 'D E E', 'D E L', 'V E V', 'E G S', 'D E S', 'L E Q L', 'Y G G T P P F V', 'D G', 'L E Q L', 'Q V A I A H R D A K', 'E E E Q', 'K G R Y E R', 'D G', 'E A G I Q', 'E A G I Q', 'N R T F', 'T A Y', 'G E G', 'A S N M S D L', 'E D D', 'E N E', 'A D E', 'V T A D E S Q Q D V L K', 'V V G E T', 'S A E Q K', 'E A', 'N R T F', 'S T M L L E S E R', 'G E']\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0125,  0.0013,  0.1073,  ..., -0.1376, -0.0970, -0.0342],\n",
      "        [ 0.0745,  0.0300, -0.0185,  ...,  0.1138, -0.0163,  0.0793],\n",
      "        [-0.0249,  0.0129,  0.1416,  ..., -0.0964, -0.1221,  0.0566],\n",
      "        ...,\n",
      "        [ 0.0582,  0.0498,  0.0815,  ..., -0.0452, -0.0270,  0.0789],\n",
      "        [ 0.0590,  0.0885,  0.0679,  ..., -0.0253,  0.0055,  0.0735],\n",
      "        [ 0.0869,  0.0188, -0.0205,  ..., -0.0127, -0.0330,  0.0567]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 40, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(test_hidden_states.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(40, 16, kernel_size=3, padding=1)  \n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * (1024 // 4), 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 40, 1024)  # Reshape to (batch_size, channels, width)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * (1024 // 4))\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for batch in train_loader:\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            print(inputs.shape)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the predicted class indices\n",
    "            train_acc += torch.sum(preds == labels.data).item()\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_acc / len(train_loader.dataset)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'\\tTraining Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}')\n",
    "        print(f'\\tValidation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "def validate(model, data_loader, criterion, device):\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch[0].to(device)\n",
    "            outputs = model(inputs)\n",
    "            labels = batch[1].to(device)  # Get the actual labels from the data loader\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the predicted class indices\n",
    "            val_acc += torch.sum(preds == labels.data).item()\n",
    "        val_loss = val_loss / len(data_loader.dataset)\n",
    "        val_acc = val_acc / len(data_loader.dataset)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "dataset = CustomDataset(hidden_states, y_train)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataset = CustomDataset(test_hidden_states, y_test)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([32, 40, 1024])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_env/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the model\n",
    "model = CNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Convert the hidden states to a PyTorch tensor\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(hidden_states)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (89x9690 and 6630x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m     test_hidden_states \u001b[38;5;241m=\u001b[39m test_hidden_states\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_hidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mCNNClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Permute to (1, 1024, 5) for Conv1d\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (89x9690 and 6630x2)"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_test = torch.tensor(y_test.values)\n",
    "with torch.no_grad():\n",
    "    test_hidden_states = test_hidden_states.detach()\n",
    "    output = model(test_hidden_states)\n",
    "    print(output)\n",
    "    print(output.shape)\n",
    "    print(y_test)\n",
    "    print(y_test.shape)\n",
    "    loss = criterion(output, y_test)\n",
    "    print(f\"Test Loss: {loss.item()}\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the accuracy\n",
    "_, predicted = torch.max(output, 1)\n",
    "correct = (predicted == y_test).sum().item()\n",
    "accuracy = correct / y_test.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 40, 1024)]        0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 39, 128)           262272    \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 39, 64)            8256      \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,674\n",
      "Trainable params: 272,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:829\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_value, _dtypes\u001b[38;5;241m.\u001b[39mDType):\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[type_value\u001b[38;5;241m.\u001b[39mas_datatype_enum]\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert the argument `type_value`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_value\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a TensorFlow DType.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "#run the model\n",
    "model = build_CNN_classifier_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(hidden_states, y_train, epochs=10, batch_size=32, validation_data=(test_hidden_states, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing data for input \"input_2\". You passed a data dictionary with keys ['last_hidden_state', 'pooler_output']. Expected the following keys: ['input_2']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bitter_classifier \u001b[38;5;241m=\u001b[39m build_CNN_classifier_model()\n\u001b[0;32m----> 2\u001b[0m output_test \u001b[38;5;241m=\u001b[39m \u001b[43mbitter_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_outputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# tensor [batch_size, max_length, 1024]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m output_test\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/pavit21178/anaconda3/envs/my_env/lib/python3.9/site-packages/keras/engine/input_spec.py:197\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing data for input \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a data dictionary with keys \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the following keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         )\n\u001b[1;32m    203\u001b[0m     list_inputs\u001b[38;5;241m.\u001b[39mappend(inputs[name])\n\u001b[1;32m    204\u001b[0m inputs \u001b[38;5;241m=\u001b[39m list_inputs\n",
      "\u001b[0;31mValueError\u001b[0m: Missing data for input \"input_2\". You passed a data dictionary with keys ['last_hidden_state', 'pooler_output']. Expected the following keys: ['input_2']"
     ]
    }
   ],
   "source": [
    "bitter_classifier = build_CNN_classifier_model()\n",
    "output_test = bitter_classifier(test_outputs) # tensor [batch_size, max_length, 1024]\n",
    "output_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
