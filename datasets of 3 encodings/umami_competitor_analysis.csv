Model_Name,Primary_Authors_of_Model,Reported_By_Evaluated_By,Year_of_Model_Publication,Task_Key_Dataset_Feature,Model_Architecture_Key_Features,Accuracy_ACC,Sensitivity_Recall,Specificity,ROC_AUC,F1_Score,Precision,MCC,Balanced_Accuracy_BACC,Notes_Evaluation_Context
TabPFN (Umami Classification),Dutta et al.,Dutta et al.,2024,"Umami vs. Non-Umami (Combined Patent + UMP442; Full Test Set: 693 train, 174 test)",TabPFN (transformer-based),0.93,0.93,0.93,0.93,0.93,N/R,N/R,0.93,Performance on their full Test Set
DNN (Umami Potency),Dutta et al.,Dutta et al.,2024,"High vs. Low Potency (EC50 < 2 ÂµM; Patent Data Test: 239 train after SMOTE, 60 test)",DNN (multilayer perceptron),0.82,0.90,N/R,N/R,0.89,0.88,N/R,N/R,Predicting potency as binary classification
TabPFN (Umami Classification - UMP-IND eval),Dutta et al.,Dutta et al.,2024,"Umami vs. Non-Umami (UMP-IND set: 28 umami, 61 non-umami)",TabPFN (transformer-based),0.899,0.821,0.934,0.878,N/R,N/R,N/R,N/R,Dutta's model evaluated on specific UMP-IND subset for comparison
ProtBert-CNN,Pandiyan et al.,Pandiyan et al.,preprint,Umami Peptide vs. Bitter Peptide (UMP-TR/IND + literature; 5-fold CV),ProtBert encoder + CNN classifier,0.94,0.98,0.89,0.954,0.929,N/R,0.891,N/R,Their best performing model
ESM-2-CNN,Pandiyan et al.,Pandiyan et al.,preprint,Umami Peptide vs. Bitter Peptide (UMP-TR/IND + literature; 5-fold CV),ESM-2 encoder + CNN classifier,0.86,0.92,0.80,0.865,0.851,N/R,0.725,N/R,
ESM-2-DNN,Pandiyan et al.,Pandiyan et al.,preprint,Umami Peptide vs. Bitter Peptide (UMP-TR/IND + literature; 5-fold CV),ESM-2 encoder + DNN classifier,0.82,0.88,0.76,0.824,0.824,N/R,0.644,N/R,
ProtBert-DNN,Pandiyan et al.,Pandiyan et al.,preprint,Umami Peptide vs. Bitter Peptide (UMP-TR/IND + literature; 5-fold CV),ProtBert encoder + DNN classifier,0.76,0.89,0.58,0.771,0.666,N/R,0.501,N/R,
iUmami-SCM [16],Charoenkwan et al.,Dutta et al. (evaluating),2020,Umami vs. Non-Umami (UMP-IND set),Scoring Card Method (SCM),0.865,0.714,0.934,0.898,N/R,N/R,N/R,N/R,As evaluated by Dutta et al. on UMP-IND
UMPred-FRL [17],Charoenkwan et al.,Dutta et al. (evaluating),2021,Umami vs. Non-Umami (UMP-IND set),"Machine Learning (multiple algorithms), feature representation learning",0.888,0.786,0.934,0.919,N/R,N/R,N/R,N/R,As evaluated by Dutta et al. on UMP-IND
VirtuousUmami [18],Pallante et al.,Dutta et al. (evaluating),2022,Umami vs. Non-Umami (UMP-IND set),"SMILES-derived descriptors, ML",0.876,0.786,0.918,0.85,N/R,N/R,N/R,N/R,As evaluated by Dutta et al. on UMP-IND
iUmami-SCM,Charoenkwan et al.,Charoenkwan et al. (cited by Pandiyan),2020,Umami Peptide Prediction (Original Paper),"Scoring Card Method (SCM), propensity scores",0.865,N/R,N/R,N/R,N/R,N/R,0.679,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al. from original publication
VirtuousUmami,Pallante et al.,Pallante et al. (cited by Pandiyan),2022,Umami Compound Prediction (Original Paper),"Peptides & natural compounds, SMILES-derived descriptors, Multi-objective ML",0.876,N/R,N/R,N/R,0.793,N/R,NA,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al.; F1 mentioned in Pandiyan's text
UMPred-FRL,Charoenkwan et al.,Charoenkwan et al. (cited by Pandiyan),2021,Umami Peptide Prediction (Original Paper),"Machine Learning, feature representation learning",0.889,N/R,N/R,N/R,N/R,N/R,0.735,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al. from original publication
IUP-BERT,Jiang et al.,Jiang et al. (cited by Pandiyan),2022,Umami Peptide Prediction (Original Paper),"BERT features, SMOTE, SVM",0.896,N/R,N/R,N/R,N/R,N/R,0.793,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al. from original publication
Umami-MRNN,Qi et al.,Qi et al. (cited by Pandiyan),2023,Umami Peptide Prediction (Original Paper),"Merged Multi-layer Perceptron and Recurrent Neural Network (MRNN), 6 feature vectors",0.905,N/R,N/R,N/R,N/R,N/R,0.811,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al. from original publication
Umami_YYDS,Cui et al.,Cui et al. (cited by Pandiyan),2023,Umami/Bitter Classification (Original Paper),Part of TastePeptides-Meta; XGBoost on 8 molecular descriptors,0.896,N/R,N/R,N/R,N/R,N/R,NA,N/R (BACC/ACC specified by Pandiyan),Cited by Pandiyan et al. from original publication
